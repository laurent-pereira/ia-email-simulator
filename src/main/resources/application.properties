#The timeout to wait for running requests to finish.
#quarkus.shutdown.timeout=120

# Generator - small, fast model
quarkus.langchain4j.generator.chat-model.model-name=phi3:mini
quarkus.langchain4j.generator.chat-model.temperature=0.8
quarkus.langchain4j.generator.chat-model.max-tokens=200
quarkus.langchain4j.generator.timeout=180s

# Processor - larger model with tool-calling
quarkus.langchain4j.processor.chat-model.model-name=llama3
quarkus.langchain4j.processor.chat-model.temperature=0.2
quarkus.langchain4j.processor.chat-model.max-tokens=100
quarkus.langchain4j.processor.timeout=180s

quarkus.langchain4j.ollama.timeout=180s
quarkus.langchain4j.ollama.base-url=http://localhost:11434

quarkus.scheduler.enabled=true
